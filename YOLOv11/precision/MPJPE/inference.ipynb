{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El MPJPE (Mean Per Joint Position Error) \n",
    "\n",
    "Es una métrica comúnmente utilizada para evaluar la precisión de los modelos de estimación de pose. Calcula la distancia promedio entre las posiciones predichas y las posiciones reales (ground truth) de las articulaciones (joints) en un espacio 3D o 2D.\n",
    "\n",
    "La distancia euclidiana se calcula con la siguiente formula\n",
    "\n",
    "![distancia euclidiana](distancia_euclidiana.png)\n",
    "\n",
    "Donde:\n",
    "- _p,q_ son dos puntos en el espacio n euclidiano\n",
    "- _qi, pi_ son vectores euclidianos a partir del origen del espacio\n",
    "- _n_ es el espacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib , mpjpe, pandas as pd # Importar importlib para recargar módulos\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "dotenv_path = os.path.join(os.getcwd(), '..', '.env')\n",
    "importlib.reload(mpjpe)\n",
    "from mpjpe import MPJPE\n",
    "\n",
    "# Configuracion\n",
    "images_path = os.path.join(os.getenv('BASE_PATH'), os.getenv('IMAGES_SUBPATH'))\n",
    "labels_path = os.path.join(os.getenv('BASE_PATH'), os.getenv('LABELS_SUBPATH'))\n",
    "evaluator = MPJPE(os.getenv('BASE_PATH'), images_path, labels_path)\n",
    "thresholds = [0.1, 0.5, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluando una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_011_jpg.rf.efc4f6570869d250cc6316a35f6b4b26.jpg: 640x384 1 person, 84.2ms\n",
      "Speed: 2.8ms preprocess, 84.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_011_jpg.rf.efc4f6570869d250cc6316a35f6b4b26.jpg: 640x384 1 person, 65.4ms\n",
      "Speed: 1.1ms preprocess, 65.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_011_jpg.rf.efc4f6570869d250cc6316a35f6b4b26.jpg: 640x384 1 person, 66.5ms\n",
      "Speed: 0.9ms preprocess, 66.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "image = 'imagen_011_jpg.rf.efc4f6570869d250cc6316a35f6b4b26.jpg'\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    results = evaluator.evaluate_image(image, threshold, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluando multiples imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_002_jpg.rf.39766b197a04d8d1569b3e546fd07390.jpg: 640x384 1 person, 79.6ms\n",
      "Speed: 1.3ms preprocess, 79.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_002_jpg.rf.39766b197a04d8d1569b3e546fd07390.jpg: 640x384 1 person, 68.6ms\n",
      "Speed: 1.0ms preprocess, 68.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_002_jpg.rf.39766b197a04d8d1569b3e546fd07390.jpg: 640x384 1 person, 64.7ms\n",
      "Speed: 1.0ms preprocess, 64.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_003_jpg.rf.212077a70b1de84df04262b03db57f65.jpg: 640x384 1 person, 63.5ms\n",
      "Speed: 1.0ms preprocess, 63.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_003_jpg.rf.212077a70b1de84df04262b03db57f65.jpg: 640x384 1 person, 66.0ms\n",
      "Speed: 1.2ms preprocess, 66.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_003_jpg.rf.212077a70b1de84df04262b03db57f65.jpg: 640x384 1 person, 69.7ms\n",
      "Speed: 1.2ms preprocess, 69.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_004_jpg.rf.4989fa64a1816f9648b130cd037da4c0.jpg: 640x384 1 person, 66.4ms\n",
      "Speed: 1.0ms preprocess, 66.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_004_jpg.rf.4989fa64a1816f9648b130cd037da4c0.jpg: 640x384 1 person, 71.7ms\n",
      "Speed: 1.0ms preprocess, 71.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_004_jpg.rf.4989fa64a1816f9648b130cd037da4c0.jpg: 640x384 1 person, 72.2ms\n",
      "Speed: 1.1ms preprocess, 72.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_005_jpg.rf.6fa127bc74f8ab541befa56df6976a55.jpg: 640x384 1 person, 76.0ms\n",
      "Speed: 1.2ms preprocess, 76.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_005_jpg.rf.6fa127bc74f8ab541befa56df6976a55.jpg: 640x384 1 person, 76.6ms\n",
      "Speed: 1.3ms preprocess, 76.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_005_jpg.rf.6fa127bc74f8ab541befa56df6976a55.jpg: 640x384 1 person, 72.2ms\n",
      "Speed: 1.1ms preprocess, 72.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_006_jpg.rf.f9e4e2609ee3c557ed403d37504f89bf.jpg: 640x384 1 person, 66.7ms\n",
      "Speed: 1.2ms preprocess, 66.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_006_jpg.rf.f9e4e2609ee3c557ed403d37504f89bf.jpg: 640x384 1 person, 65.5ms\n",
      "Speed: 0.9ms preprocess, 65.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_006_jpg.rf.f9e4e2609ee3c557ed403d37504f89bf.jpg: 640x384 1 person, 67.3ms\n",
      "Speed: 0.9ms preprocess, 67.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_007_jpg.rf.427bc5600e403e5fbbab27a114f10306.jpg: 640x384 1 person, 69.5ms\n",
      "Speed: 1.0ms preprocess, 69.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_007_jpg.rf.427bc5600e403e5fbbab27a114f10306.jpg: 640x384 1 person, 77.5ms\n",
      "Speed: 0.9ms preprocess, 77.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_007_jpg.rf.427bc5600e403e5fbbab27a114f10306.jpg: 640x384 1 person, 74.7ms\n",
      "Speed: 1.4ms preprocess, 74.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_008_jpg.rf.00700f922d37da70606fa16130a5d9a7.jpg: 640x384 1 person, 67.0ms\n",
      "Speed: 1.1ms preprocess, 67.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_008_jpg.rf.00700f922d37da70606fa16130a5d9a7.jpg: 640x384 1 person, 65.5ms\n",
      "Speed: 1.0ms preprocess, 65.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_008_jpg.rf.00700f922d37da70606fa16130a5d9a7.jpg: 640x384 1 person, 84.7ms\n",
      "Speed: 1.1ms preprocess, 84.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_009_jpg.rf.edc93a9e00958f5569e22157b0aefe83.jpg: 640x384 1 person, 68.7ms\n",
      "Speed: 1.0ms preprocess, 68.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_009_jpg.rf.edc93a9e00958f5569e22157b0aefe83.jpg: 640x384 1 person, 69.4ms\n",
      "Speed: 1.0ms preprocess, 69.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_009_jpg.rf.edc93a9e00958f5569e22157b0aefe83.jpg: 640x384 1 person, 69.6ms\n",
      "Speed: 1.1ms preprocess, 69.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_010_jpg.rf.adf365bd7315f99371253648fc784b87.jpg: 640x384 1 person, 77.8ms\n",
      "Speed: 1.0ms preprocess, 77.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_010_jpg.rf.adf365bd7315f99371253648fc784b87.jpg: 640x384 1 person, 65.0ms\n",
      "Speed: 1.2ms preprocess, 65.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_010_jpg.rf.adf365bd7315f99371253648fc784b87.jpg: 640x384 1 person, 64.1ms\n",
      "Speed: 0.9ms preprocess, 64.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_011_jpg.rf.efc4f6570869d250cc6316a35f6b4b26.jpg: 640x384 1 person, 67.1ms\n",
      "Speed: 0.9ms preprocess, 67.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_011_jpg.rf.efc4f6570869d250cc6316a35f6b4b26.jpg: 640x384 1 person, 64.2ms\n",
      "Speed: 1.0ms preprocess, 64.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_011_jpg.rf.efc4f6570869d250cc6316a35f6b4b26.jpg: 640x384 1 person, 63.6ms\n",
      "Speed: 1.1ms preprocess, 63.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_012_jpg.rf.73579363caeccc19c4ce66fcc36a6b35.jpg: 640x384 1 person, 65.3ms\n",
      "Speed: 0.9ms preprocess, 65.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_012_jpg.rf.73579363caeccc19c4ce66fcc36a6b35.jpg: 640x384 1 person, 62.7ms\n",
      "Speed: 1.1ms preprocess, 62.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_012_jpg.rf.73579363caeccc19c4ce66fcc36a6b35.jpg: 640x384 1 person, 71.9ms\n",
      "Speed: 0.9ms preprocess, 71.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_013_jpg.rf.d8bbed7435222a80c55481d03c35ed33.jpg: 640x384 1 person, 116.2ms\n",
      "Speed: 1.3ms preprocess, 116.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_013_jpg.rf.d8bbed7435222a80c55481d03c35ed33.jpg: 640x384 1 person, 152.9ms\n",
      "Speed: 6.4ms preprocess, 152.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_013_jpg.rf.d8bbed7435222a80c55481d03c35ed33.jpg: 640x384 1 person, 78.8ms\n",
      "Speed: 1.2ms preprocess, 78.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_014_jpg.rf.9b73844fd1a58e6de1dd2cd81aca8dc6.jpg: 640x384 1 person, 77.9ms\n",
      "Speed: 1.1ms preprocess, 77.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_014_jpg.rf.9b73844fd1a58e6de1dd2cd81aca8dc6.jpg: 640x384 1 person, 76.9ms\n",
      "Speed: 1.1ms preprocess, 76.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_014_jpg.rf.9b73844fd1a58e6de1dd2cd81aca8dc6.jpg: 640x384 1 person, 86.1ms\n",
      "Speed: 1.5ms preprocess, 86.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_015_jpg.rf.f9f4a2f961f83fa157ea9589e10e6ef9.jpg: 640x384 1 person, 80.6ms\n",
      "Speed: 1.4ms preprocess, 80.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_015_jpg.rf.f9f4a2f961f83fa157ea9589e10e6ef9.jpg: 640x384 1 person, 73.7ms\n",
      "Speed: 1.4ms preprocess, 73.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_015_jpg.rf.f9f4a2f961f83fa157ea9589e10e6ef9.jpg: 640x384 1 person, 73.5ms\n",
      "Speed: 1.1ms preprocess, 73.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_016_jpg.rf.a61e7103d22003e613caff715cc2e6af.jpg: 640x384 1 person, 68.8ms\n",
      "Speed: 1.0ms preprocess, 68.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_016_jpg.rf.a61e7103d22003e613caff715cc2e6af.jpg: 640x384 1 person, 68.9ms\n",
      "Speed: 1.1ms preprocess, 68.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_016_jpg.rf.a61e7103d22003e613caff715cc2e6af.jpg: 640x384 1 person, 72.7ms\n",
      "Speed: 1.0ms preprocess, 72.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_017_jpg.rf.122563551b80765ec9c83d234d55aa60.jpg: 640x384 1 person, 67.6ms\n",
      "Speed: 1.0ms preprocess, 67.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_017_jpg.rf.122563551b80765ec9c83d234d55aa60.jpg: 640x384 1 person, 71.0ms\n",
      "Speed: 1.0ms preprocess, 71.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_017_jpg.rf.122563551b80765ec9c83d234d55aa60.jpg: 640x384 1 person, 70.7ms\n",
      "Speed: 1.2ms preprocess, 70.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_018_jpg.rf.89572f27131b84f8ab944e1f5d299838.jpg: 640x384 1 person, 67.4ms\n",
      "Speed: 1.2ms preprocess, 67.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_018_jpg.rf.89572f27131b84f8ab944e1f5d299838.jpg: 640x384 1 person, 68.3ms\n",
      "Speed: 0.9ms preprocess, 68.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_018_jpg.rf.89572f27131b84f8ab944e1f5d299838.jpg: 640x384 1 person, 68.7ms\n",
      "Speed: 1.0ms preprocess, 68.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_019_jpg.rf.1d44dd10c5ccd440fe9c42d687a33f78.jpg: 640x384 1 person, 69.6ms\n",
      "Speed: 1.1ms preprocess, 69.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_019_jpg.rf.1d44dd10c5ccd440fe9c42d687a33f78.jpg: 640x384 1 person, 68.5ms\n",
      "Speed: 0.9ms preprocess, 68.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_019_jpg.rf.1d44dd10c5ccd440fe9c42d687a33f78.jpg: 640x384 1 person, 119.8ms\n",
      "Speed: 1.0ms preprocess, 119.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_020_jpg.rf.9c03ec029de8f9b271b3e70f2460eb43.jpg: 640x384 1 person, 69.4ms\n",
      "Speed: 1.1ms preprocess, 69.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_020_jpg.rf.9c03ec029de8f9b271b3e70f2460eb43.jpg: 640x384 1 person, 66.9ms\n",
      "Speed: 0.9ms preprocess, 66.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_020_jpg.rf.9c03ec029de8f9b271b3e70f2460eb43.jpg: 640x384 1 person, 66.5ms\n",
      "Speed: 1.0ms preprocess, 66.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_021_jpg.rf.d5d819dec165988997ada2c000f85db7.jpg: 640x384 1 person, 68.2ms\n",
      "Speed: 1.0ms preprocess, 68.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_021_jpg.rf.d5d819dec165988997ada2c000f85db7.jpg: 640x384 1 person, 68.5ms\n",
      "Speed: 1.0ms preprocess, 68.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_021_jpg.rf.d5d819dec165988997ada2c000f85db7.jpg: 640x384 1 person, 71.4ms\n",
      "Speed: 0.9ms preprocess, 71.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_022_jpg.rf.214ee4f4dda73001da2ce8300a2f4a67.jpg: 640x384 1 person, 79.2ms\n",
      "Speed: 1.2ms preprocess, 79.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_022_jpg.rf.214ee4f4dda73001da2ce8300a2f4a67.jpg: 640x384 1 person, 76.7ms\n",
      "Speed: 1.1ms preprocess, 76.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_022_jpg.rf.214ee4f4dda73001da2ce8300a2f4a67.jpg: 640x384 1 person, 73.5ms\n",
      "Speed: 1.2ms preprocess, 73.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_023_jpg.rf.8f0cfbd8b70cadbb42b155858dcdb72b.jpg: 640x384 1 person, 68.1ms\n",
      "Speed: 1.0ms preprocess, 68.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_023_jpg.rf.8f0cfbd8b70cadbb42b155858dcdb72b.jpg: 640x384 1 person, 76.9ms\n",
      "Speed: 0.8ms preprocess, 76.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_023_jpg.rf.8f0cfbd8b70cadbb42b155858dcdb72b.jpg: 640x384 1 person, 118.3ms\n",
      "Speed: 1.4ms preprocess, 118.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_024_jpg.rf.9cad3999761a117ebea758d708d5d531.jpg: 640x384 1 person, 95.1ms\n",
      "Speed: 1.7ms preprocess, 95.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_024_jpg.rf.9cad3999761a117ebea758d708d5d531.jpg: 640x384 1 person, 74.0ms\n",
      "Speed: 1.1ms preprocess, 74.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_024_jpg.rf.9cad3999761a117ebea758d708d5d531.jpg: 640x384 1 person, 80.3ms\n",
      "Speed: 1.1ms preprocess, 80.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_025_jpg.rf.dd1e1b53eff2e467abc7dde760affdc4.jpg: 640x384 1 person, 82.2ms\n",
      "Speed: 1.5ms preprocess, 82.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_025_jpg.rf.dd1e1b53eff2e467abc7dde760affdc4.jpg: 640x384 1 person, 92.3ms\n",
      "Speed: 1.1ms preprocess, 92.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_025_jpg.rf.dd1e1b53eff2e467abc7dde760affdc4.jpg: 640x384 1 person, 77.5ms\n",
      "Speed: 1.2ms preprocess, 77.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_026_jpg.rf.851e25cc58b9f2a2d43793f77c1906fe.jpg: 640x384 1 person, 67.1ms\n",
      "Speed: 1.0ms preprocess, 67.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_026_jpg.rf.851e25cc58b9f2a2d43793f77c1906fe.jpg: 640x384 1 person, 112.9ms\n",
      "Speed: 1.5ms preprocess, 112.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_026_jpg.rf.851e25cc58b9f2a2d43793f77c1906fe.jpg: 640x384 1 person, 78.9ms\n",
      "Speed: 1.5ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_027_jpg.rf.3c0305eaebd7af92343d5a7a5c97e20c.jpg: 640x384 1 person, 67.2ms\n",
      "Speed: 1.0ms preprocess, 67.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_027_jpg.rf.3c0305eaebd7af92343d5a7a5c97e20c.jpg: 640x384 1 person, 71.0ms\n",
      "Speed: 1.1ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_027_jpg.rf.3c0305eaebd7af92343d5a7a5c97e20c.jpg: 640x384 1 person, 75.4ms\n",
      "Speed: 0.9ms preprocess, 75.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_028_jpg.rf.b7b6281a45df236d7e3d2eb19c96b575.jpg: 640x384 1 person, 71.7ms\n",
      "Speed: 1.2ms preprocess, 71.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_028_jpg.rf.b7b6281a45df236d7e3d2eb19c96b575.jpg: 640x384 1 person, 73.2ms\n",
      "Speed: 1.1ms preprocess, 73.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_028_jpg.rf.b7b6281a45df236d7e3d2eb19c96b575.jpg: 640x384 1 person, 62.3ms\n",
      "Speed: 1.1ms preprocess, 62.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_029_jpg.rf.d8b47801f5d71941a9bec7ebcc64be98.jpg: 640x384 1 person, 73.3ms\n",
      "Speed: 1.0ms preprocess, 73.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_029_jpg.rf.d8b47801f5d71941a9bec7ebcc64be98.jpg: 640x384 1 person, 164.9ms\n",
      "Speed: 1.9ms preprocess, 164.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_029_jpg.rf.d8b47801f5d71941a9bec7ebcc64be98.jpg: 640x384 1 person, 68.4ms\n",
      "Speed: 1.3ms preprocess, 68.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_030_jpg.rf.da5e9d05544f94084a2875e82c78fef5.jpg: 640x384 1 person, 72.6ms\n",
      "Speed: 1.1ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_030_jpg.rf.da5e9d05544f94084a2875e82c78fef5.jpg: 640x384 1 person, 66.0ms\n",
      "Speed: 1.4ms preprocess, 66.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_030_jpg.rf.da5e9d05544f94084a2875e82c78fef5.jpg: 640x384 1 person, 63.7ms\n",
      "Speed: 0.9ms preprocess, 63.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_031_jpg.rf.d01ad07675500025673f27e8f15b67dd.jpg: 640x384 1 person, 62.7ms\n",
      "Speed: 1.0ms preprocess, 62.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_031_jpg.rf.d01ad07675500025673f27e8f15b67dd.jpg: 640x384 1 person, 62.2ms\n",
      "Speed: 1.2ms preprocess, 62.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_031_jpg.rf.d01ad07675500025673f27e8f15b67dd.jpg: 640x384 1 person, 62.8ms\n",
      "Speed: 1.0ms preprocess, 62.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_032_jpg.rf.b8b00062a3ef0404d4c8cb80377aa035.jpg: 640x384 1 person, 64.2ms\n",
      "Speed: 1.0ms preprocess, 64.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_032_jpg.rf.b8b00062a3ef0404d4c8cb80377aa035.jpg: 640x384 1 person, 68.4ms\n",
      "Speed: 1.1ms preprocess, 68.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_032_jpg.rf.b8b00062a3ef0404d4c8cb80377aa035.jpg: 640x384 1 person, 71.7ms\n",
      "Speed: 1.2ms preprocess, 71.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_033_jpg.rf.7724586b779fee811c980439acc5edcb.jpg: 640x384 1 person, 68.1ms\n",
      "Speed: 1.2ms preprocess, 68.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_033_jpg.rf.7724586b779fee811c980439acc5edcb.jpg: 640x384 1 person, 63.4ms\n",
      "Speed: 1.0ms preprocess, 63.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_033_jpg.rf.7724586b779fee811c980439acc5edcb.jpg: 640x384 1 person, 64.8ms\n",
      "Speed: 1.0ms preprocess, 64.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_034_jpg.rf.39eb787eb373897e2b43cad66dd09652.jpg: 640x384 1 person, 66.6ms\n",
      "Speed: 1.1ms preprocess, 66.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_034_jpg.rf.39eb787eb373897e2b43cad66dd09652.jpg: 640x384 1 person, 72.4ms\n",
      "Speed: 1.0ms preprocess, 72.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_034_jpg.rf.39eb787eb373897e2b43cad66dd09652.jpg: 640x384 1 person, 84.5ms\n",
      "Speed: 1.4ms preprocess, 84.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_035_jpg.rf.0b77a8999db2010cee67cb50a23f19fe.jpg: 640x384 1 person, 73.6ms\n",
      "Speed: 1.2ms preprocess, 73.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_035_jpg.rf.0b77a8999db2010cee67cb50a23f19fe.jpg: 640x384 1 person, 67.1ms\n",
      "Speed: 1.0ms preprocess, 67.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_035_jpg.rf.0b77a8999db2010cee67cb50a23f19fe.jpg: 640x384 1 person, 73.2ms\n",
      "Speed: 1.1ms preprocess, 73.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_036_jpg.rf.9905947b219a327992240e16e4cffe2e.jpg: 640x384 1 person, 78.9ms\n",
      "Speed: 1.1ms preprocess, 78.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_036_jpg.rf.9905947b219a327992240e16e4cffe2e.jpg: 640x384 1 person, 67.3ms\n",
      "Speed: 1.3ms preprocess, 67.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_036_jpg.rf.9905947b219a327992240e16e4cffe2e.jpg: 640x384 1 person, 62.5ms\n",
      "Speed: 1.0ms preprocess, 62.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_037_jpg.rf.997c4d474418759b01640e08dffd94b9.jpg: 640x384 1 person, 63.0ms\n",
      "Speed: 1.0ms preprocess, 63.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_037_jpg.rf.997c4d474418759b01640e08dffd94b9.jpg: 640x384 1 person, 63.4ms\n",
      "Speed: 1.1ms preprocess, 63.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_037_jpg.rf.997c4d474418759b01640e08dffd94b9.jpg: 640x384 1 person, 61.1ms\n",
      "Speed: 1.0ms preprocess, 61.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_038_jpg.rf.a021166000b1a12178949c06dc85d6bf.jpg: 640x384 1 person, 60.8ms\n",
      "Speed: 1.0ms preprocess, 60.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_038_jpg.rf.a021166000b1a12178949c06dc85d6bf.jpg: 640x384 1 person, 61.6ms\n",
      "Speed: 1.0ms preprocess, 61.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_038_jpg.rf.a021166000b1a12178949c06dc85d6bf.jpg: 640x384 1 person, 63.4ms\n",
      "Speed: 0.9ms preprocess, 63.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_039_jpg.rf.9ac1db409b49ef60ce08d79ff1a30a48.jpg: 640x384 1 person, 66.7ms\n",
      "Speed: 1.1ms preprocess, 66.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_039_jpg.rf.9ac1db409b49ef60ce08d79ff1a30a48.jpg: 640x384 1 person, 63.2ms\n",
      "Speed: 1.0ms preprocess, 63.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_039_jpg.rf.9ac1db409b49ef60ce08d79ff1a30a48.jpg: 640x384 1 person, 60.8ms\n",
      "Speed: 1.0ms preprocess, 60.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_040_jpg.rf.d710dd5ec7f87c241d380f2d9da1357b.jpg: 640x384 1 person, 61.6ms\n",
      "Speed: 0.9ms preprocess, 61.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_040_jpg.rf.d710dd5ec7f87c241d380f2d9da1357b.jpg: 640x384 1 person, 65.2ms\n",
      "Speed: 1.0ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_040_jpg.rf.d710dd5ec7f87c241d380f2d9da1357b.jpg: 640x384 1 person, 75.5ms\n",
      "Speed: 0.9ms preprocess, 75.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_041_jpg.rf.11eb3a677e68ec76681752ea3a3dbf47.jpg: 640x384 1 person, 65.4ms\n",
      "Speed: 1.1ms preprocess, 65.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_041_jpg.rf.11eb3a677e68ec76681752ea3a3dbf47.jpg: 640x384 1 person, 67.3ms\n",
      "Speed: 1.3ms preprocess, 67.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_041_jpg.rf.11eb3a677e68ec76681752ea3a3dbf47.jpg: 640x384 1 person, 70.4ms\n",
      "Speed: 1.2ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_042_jpg.rf.a74fe8a0b48800340d2a64e414174c99.jpg: 640x384 1 person, 75.2ms\n",
      "Speed: 1.6ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_042_jpg.rf.a74fe8a0b48800340d2a64e414174c99.jpg: 640x384 1 person, 74.4ms\n",
      "Speed: 1.4ms preprocess, 74.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_042_jpg.rf.a74fe8a0b48800340d2a64e414174c99.jpg: 640x384 1 person, 62.6ms\n",
      "Speed: 1.0ms preprocess, 62.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_043_jpg.rf.48f7666a8b703183e93c71017af8ede5.jpg: 640x384 1 person, 63.2ms\n",
      "Speed: 1.0ms preprocess, 63.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_043_jpg.rf.48f7666a8b703183e93c71017af8ede5.jpg: 640x384 1 person, 61.1ms\n",
      "Speed: 1.0ms preprocess, 61.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_043_jpg.rf.48f7666a8b703183e93c71017af8ede5.jpg: 640x384 1 person, 60.8ms\n",
      "Speed: 1.1ms preprocess, 60.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_044_jpg.rf.5dafc86c508894b71d5398319b032c77.jpg: 640x384 1 person, 64.5ms\n",
      "Speed: 1.0ms preprocess, 64.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_044_jpg.rf.5dafc86c508894b71d5398319b032c77.jpg: 640x384 1 person, 70.7ms\n",
      "Speed: 1.1ms preprocess, 70.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_044_jpg.rf.5dafc86c508894b71d5398319b032c77.jpg: 640x384 1 person, 66.4ms\n",
      "Speed: 1.2ms preprocess, 66.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_045_jpg.rf.740381672d954a588fb578615e7a9309.jpg: 640x384 1 person, 62.8ms\n",
      "Speed: 1.0ms preprocess, 62.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_045_jpg.rf.740381672d954a588fb578615e7a9309.jpg: 640x384 1 person, 96.5ms\n",
      "Speed: 1.2ms preprocess, 96.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_045_jpg.rf.740381672d954a588fb578615e7a9309.jpg: 640x384 1 person, 135.2ms\n",
      "Speed: 1.8ms preprocess, 135.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_046_jpg.rf.2e0fddc0b0396f4f8c7986335f618478.jpg: 640x384 1 person, 78.1ms\n",
      "Speed: 1.2ms preprocess, 78.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_046_jpg.rf.2e0fddc0b0396f4f8c7986335f618478.jpg: 640x384 1 person, 79.5ms\n",
      "Speed: 1.1ms preprocess, 79.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_046_jpg.rf.2e0fddc0b0396f4f8c7986335f618478.jpg: 640x384 1 person, 92.0ms\n",
      "Speed: 1.3ms preprocess, 92.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_047_jpg.rf.3b9b9d7cea0263619730ac88080552d3.jpg: 640x384 1 person, 68.5ms\n",
      "Speed: 1.2ms preprocess, 68.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_047_jpg.rf.3b9b9d7cea0263619730ac88080552d3.jpg: 640x384 1 person, 67.8ms\n",
      "Speed: 1.3ms preprocess, 67.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_047_jpg.rf.3b9b9d7cea0263619730ac88080552d3.jpg: 640x384 1 person, 70.1ms\n",
      "Speed: 0.8ms preprocess, 70.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_048_jpg.rf.a8aba5d7117f1601a363c89ba10667d0.jpg: 640x384 1 person, 68.3ms\n",
      "Speed: 1.1ms preprocess, 68.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_048_jpg.rf.a8aba5d7117f1601a363c89ba10667d0.jpg: 640x384 1 person, 69.1ms\n",
      "Speed: 1.1ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_048_jpg.rf.a8aba5d7117f1601a363c89ba10667d0.jpg: 640x384 1 person, 68.7ms\n",
      "Speed: 0.9ms preprocess, 68.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_049_jpg.rf.b73da4e6df97e30e7591bb4db61a2005.jpg: 640x352 1 person, 78.3ms\n",
      "Speed: 1.2ms preprocess, 78.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 352)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_049_jpg.rf.b73da4e6df97e30e7591bb4db61a2005.jpg: 640x352 1 person, 67.0ms\n",
      "Speed: 1.0ms preprocess, 67.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 352)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_049_jpg.rf.b73da4e6df97e30e7591bb4db61a2005.jpg: 640x352 1 person, 64.2ms\n",
      "Speed: 1.0ms preprocess, 64.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 352)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_050_jpg.rf.90b9aab729a8161d81784b429b40743a.jpg: 640x384 1 person, 65.7ms\n",
      "Speed: 1.2ms preprocess, 65.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_050_jpg.rf.90b9aab729a8161d81784b429b40743a.jpg: 640x384 1 person, 61.9ms\n",
      "Speed: 1.0ms preprocess, 61.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_050_jpg.rf.90b9aab729a8161d81784b429b40743a.jpg: 640x384 1 person, 71.1ms\n",
      "Speed: 1.1ms preprocess, 71.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_051_jpg.rf.ef9804b7653e74f31c13dd8db40f15da.jpg: 640x384 1 person, 71.5ms\n",
      "Speed: 1.3ms preprocess, 71.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_051_jpg.rf.ef9804b7653e74f31c13dd8db40f15da.jpg: 640x384 1 person, 65.1ms\n",
      "Speed: 1.2ms preprocess, 65.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_051_jpg.rf.ef9804b7653e74f31c13dd8db40f15da.jpg: 640x384 1 person, 60.7ms\n",
      "Speed: 1.0ms preprocess, 60.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_052_jpg.rf.99e4505426b30cc5add575c69ec73da2.jpg: 640x384 1 person, 66.5ms\n",
      "Speed: 1.0ms preprocess, 66.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_052_jpg.rf.99e4505426b30cc5add575c69ec73da2.jpg: 640x384 1 person, 72.8ms\n",
      "Speed: 1.2ms preprocess, 72.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_052_jpg.rf.99e4505426b30cc5add575c69ec73da2.jpg: 640x384 1 person, 74.0ms\n",
      "Speed: 1.2ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_053_jpg.rf.8585d5035131f411da878c525557ed28.jpg: 640x384 1 person, 71.4ms\n",
      "Speed: 1.0ms preprocess, 71.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_053_jpg.rf.8585d5035131f411da878c525557ed28.jpg: 640x384 1 person, 71.8ms\n",
      "Speed: 1.0ms preprocess, 71.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_053_jpg.rf.8585d5035131f411da878c525557ed28.jpg: 640x384 1 person, 65.3ms\n",
      "Speed: 1.0ms preprocess, 65.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_054_jpg.rf.41be28c49231a6247b5cd2261b08f1de.jpg: 640x384 1 person, 68.7ms\n",
      "Speed: 1.2ms preprocess, 68.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_054_jpg.rf.41be28c49231a6247b5cd2261b08f1de.jpg: 640x384 1 person, 67.0ms\n",
      "Speed: 1.2ms preprocess, 67.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_054_jpg.rf.41be28c49231a6247b5cd2261b08f1de.jpg: 640x384 1 person, 72.8ms\n",
      "Speed: 1.1ms preprocess, 72.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_055_jpg.rf.ef20a97116f6eaaf570f22deca14a568.jpg: 640x384 1 person, 68.3ms\n",
      "Speed: 0.9ms preprocess, 68.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_055_jpg.rf.ef20a97116f6eaaf570f22deca14a568.jpg: 640x384 1 person, 65.1ms\n",
      "Speed: 1.0ms preprocess, 65.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_055_jpg.rf.ef20a97116f6eaaf570f22deca14a568.jpg: 640x384 1 person, 69.7ms\n",
      "Speed: 1.2ms preprocess, 69.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_056_jpg.rf.91fc7bd24e391c5dfb5b5ca3b36baeb1.jpg: 640x384 1 person, 64.8ms\n",
      "Speed: 1.1ms preprocess, 64.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_056_jpg.rf.91fc7bd24e391c5dfb5b5ca3b36baeb1.jpg: 640x384 1 person, 64.8ms\n",
      "Speed: 1.0ms preprocess, 64.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_056_jpg.rf.91fc7bd24e391c5dfb5b5ca3b36baeb1.jpg: 640x384 1 person, 65.4ms\n",
      "Speed: 1.0ms preprocess, 65.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_057_jpg.rf.817ac3b1dd08c3eba3bf2ec27837e22f.jpg: 640x384 1 person, 64.5ms\n",
      "Speed: 1.0ms preprocess, 64.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_057_jpg.rf.817ac3b1dd08c3eba3bf2ec27837e22f.jpg: 640x384 1 person, 62.1ms\n",
      "Speed: 1.0ms preprocess, 62.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_057_jpg.rf.817ac3b1dd08c3eba3bf2ec27837e22f.jpg: 640x384 1 person, 64.3ms\n",
      "Speed: 1.2ms preprocess, 64.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_058_jpg.rf.1cdf5d501039211bebfc473751e5376d.jpg: 640x384 2 persons, 64.5ms\n",
      "Speed: 1.2ms preprocess, 64.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_058_jpg.rf.1cdf5d501039211bebfc473751e5376d.jpg: 640x384 2 persons, 115.5ms\n",
      "Speed: 1.0ms preprocess, 115.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_058_jpg.rf.1cdf5d501039211bebfc473751e5376d.jpg: 640x384 2 persons, 63.3ms\n",
      "Speed: 1.0ms preprocess, 63.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_059_jpg.rf.a2d57c5445e80715b121f5cf24192c9c.jpg: 640x384 1 person, 59.0ms\n",
      "Speed: 1.0ms preprocess, 59.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_059_jpg.rf.a2d57c5445e80715b121f5cf24192c9c.jpg: 640x384 1 person, 60.1ms\n",
      "Speed: 1.0ms preprocess, 60.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_059_jpg.rf.a2d57c5445e80715b121f5cf24192c9c.jpg: 640x384 1 person, 59.2ms\n",
      "Speed: 1.0ms preprocess, 59.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_060_jpg.rf.dc1483c88bd8fe66f0cd255f882c1145.jpg: 640x384 1 person, 59.4ms\n",
      "Speed: 1.0ms preprocess, 59.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_060_jpg.rf.dc1483c88bd8fe66f0cd255f882c1145.jpg: 640x384 1 person, 62.1ms\n",
      "Speed: 1.0ms preprocess, 62.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_060_jpg.rf.dc1483c88bd8fe66f0cd255f882c1145.jpg: 640x384 1 person, 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_061_jpg.rf.fd75b94ddd3e3dc0c8bcc131c16abba8.jpg: 640x384 1 person, 60.7ms\n",
      "Speed: 1.1ms preprocess, 60.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_061_jpg.rf.fd75b94ddd3e3dc0c8bcc131c16abba8.jpg: 640x384 1 person, 65.4ms\n",
      "Speed: 1.0ms preprocess, 65.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_061_jpg.rf.fd75b94ddd3e3dc0c8bcc131c16abba8.jpg: 640x384 1 person, 67.2ms\n",
      "Speed: 0.9ms preprocess, 67.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_062_jpg.rf.67b212e193dcccad590e8a4eb2dc24cc.jpg: 640x384 2 persons, 60.2ms\n",
      "Speed: 1.0ms preprocess, 60.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_062_jpg.rf.67b212e193dcccad590e8a4eb2dc24cc.jpg: 640x384 2 persons, 61.8ms\n",
      "Speed: 1.2ms preprocess, 61.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_062_jpg.rf.67b212e193dcccad590e8a4eb2dc24cc.jpg: 640x384 2 persons, 59.3ms\n",
      "Speed: 1.0ms preprocess, 59.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_063_jpg.rf.6e6053f78c39006d4f4201702e4d78b4.jpg: 640x384 1 person, 58.7ms\n",
      "Speed: 1.0ms preprocess, 58.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_063_jpg.rf.6e6053f78c39006d4f4201702e4d78b4.jpg: 640x384 1 person, 58.6ms\n",
      "Speed: 1.1ms preprocess, 58.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_063_jpg.rf.6e6053f78c39006d4f4201702e4d78b4.jpg: 640x384 1 person, 58.6ms\n",
      "Speed: 1.0ms preprocess, 58.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_064_jpg.rf.ea8838306055587be1482e596deab216.jpg: 640x384 1 person, 61.1ms\n",
      "Speed: 1.0ms preprocess, 61.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_064_jpg.rf.ea8838306055587be1482e596deab216.jpg: 640x384 1 person, 73.7ms\n",
      "Speed: 0.9ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_064_jpg.rf.ea8838306055587be1482e596deab216.jpg: 640x384 1 person, 82.8ms\n",
      "Speed: 1.3ms preprocess, 82.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_065_jpg.rf.939388d8bd5206439fbf96ec0ef0381e.jpg: 640x384 1 person, 77.3ms\n",
      "Speed: 1.0ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_065_jpg.rf.939388d8bd5206439fbf96ec0ef0381e.jpg: 640x384 1 person, 117.7ms\n",
      "Speed: 1.1ms preprocess, 117.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_065_jpg.rf.939388d8bd5206439fbf96ec0ef0381e.jpg: 640x384 1 person, 68.4ms\n",
      "Speed: 1.1ms preprocess, 68.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_066_jpg.rf.17f44222fd8fc08c7e920cb371da4ba0.jpg: 640x384 1 person, 73.2ms\n",
      "Speed: 1.0ms preprocess, 73.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_066_jpg.rf.17f44222fd8fc08c7e920cb371da4ba0.jpg: 640x384 1 person, 67.0ms\n",
      "Speed: 1.1ms preprocess, 67.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_066_jpg.rf.17f44222fd8fc08c7e920cb371da4ba0.jpg: 640x384 1 person, 66.7ms\n",
      "Speed: 1.2ms preprocess, 66.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_067_jpg.rf.9ef8934633f4efe45fc6533c76d43dd1.jpg: 640x384 1 person, 70.1ms\n",
      "Speed: 1.2ms preprocess, 70.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_067_jpg.rf.9ef8934633f4efe45fc6533c76d43dd1.jpg: 640x384 1 person, 65.8ms\n",
      "Speed: 1.2ms preprocess, 65.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_067_jpg.rf.9ef8934633f4efe45fc6533c76d43dd1.jpg: 640x384 1 person, 125.1ms\n",
      "Speed: 0.9ms preprocess, 125.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_068_jpg.rf.a0163dc53b078bf36d416ca848df5310.jpg: 640x384 1 person, 63.9ms\n",
      "Speed: 1.1ms preprocess, 63.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_068_jpg.rf.a0163dc53b078bf36d416ca848df5310.jpg: 640x384 1 person, 68.9ms\n",
      "Speed: 1.0ms preprocess, 68.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_068_jpg.rf.a0163dc53b078bf36d416ca848df5310.jpg: 640x384 1 person, 118.8ms\n",
      "Speed: 1.4ms preprocess, 118.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_069_jpg.rf.a2c90562d71acb19864f20e6b19b7dd1.jpg: 640x384 1 person, 76.6ms\n",
      "Speed: 1.4ms preprocess, 76.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_069_jpg.rf.a2c90562d71acb19864f20e6b19b7dd1.jpg: 640x384 1 person, 84.0ms\n",
      "Speed: 1.2ms preprocess, 84.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_069_jpg.rf.a2c90562d71acb19864f20e6b19b7dd1.jpg: 640x384 1 person, 78.3ms\n",
      "Speed: 1.2ms preprocess, 78.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_070_jpg.rf.60568a1aaf63e10d83beb3cee8603b0a.jpg: 640x384 1 person, 76.5ms\n",
      "Speed: 1.2ms preprocess, 76.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_070_jpg.rf.60568a1aaf63e10d83beb3cee8603b0a.jpg: 640x384 1 person, 80.6ms\n",
      "Speed: 1.4ms preprocess, 80.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n",
      "\n",
      "image 1/1 /Users/apple/Documents/pose_estimation/dataset/images/imagen_070_jpg.rf.60568a1aaf63e10d83beb3cee8603b0a.jpg: 640x384 1 person, 61.9ms\n",
      "Speed: 0.9ms preprocess, 61.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtener la lista de todas las imágenes en la carpeta\n",
    "image_files = [f for f in os.listdir(images_path) if f.endswith('.jpg')]\n",
    "image_files_sorted = sorted(image_files)\n",
    "results = []\n",
    "\n",
    "for image in image_files_sorted:\n",
    "    for threshold in thresholds:\n",
    "        results = evaluator.evaluate_image(image, threshold, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generando XLS con informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los resultados se han guardado en /Users/apple/Documents/pose_estimation/YOLOv11/precision/MPJPE/yolov11_mpjpe_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame con los resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "output_excel_path = os.path.join(os.getenv('BASE_PATH'), os.getenv('YOLO_SUBPATH'), 'precision', 'MPJPE', 'yolov11_mpjpe_results.xlsx')\n",
    "df_results.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Los resultados se han guardado en {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretacion de resultados\n",
    "\n",
    "Si el MPJPE es alto o bajo se debe considerar que\n",
    "- Las coordenadas ya se encuentran normalizadas en un valor de 0 y 1\n",
    "- En terminos de pixeles, si la imagen tiene un tamanho de 256 x 256, el error promedio (5.54%) seria **mpjep x pixeles**, ej. 0.055465 x 256 = 14.19, esto significa que las predicciones estan desviadas por aproximadamente 14.19 pixeles de las reales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
